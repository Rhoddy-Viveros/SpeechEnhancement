{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feea9f5b",
   "metadata": {},
   "source": [
    "# Desarrollo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "670a1010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import sklearn.model_selection\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from ignite.engine import  Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, Metric\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from codes import utils\n",
    "from codes import metric as mt\n",
    "from codes.dataset2 import WetSoundDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid\n",
    "from codes.models import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86a6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6d6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa79b3e",
   "metadata": {},
   "source": [
    "## 1. Importación y pre-procesamiento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73fe65b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 4\n",
    "AUDIO_DIR = os.path.join(main,\"features/train_set/\")\n",
    "SAMPLE_RATE = 44100\n",
    "LEN_SEC = 300\n",
    "LEN_SAMPLES = LEN_SEC*SAMPLE_RATE\n",
    "NUM_SAMPLES = 1292   #Cantidad de secuencias , no largo de secuencia 12920/40\n",
    "__class_labels = {\n",
    "'perro'    : 0,\n",
    "'rana'     : 1,\n",
    "'lluvia'   : 2,\n",
    "'motor'    : 3,\n",
    "'ave'      : 4\n",
    "}\n",
    "N_FFT = 2048\n",
    "HOP = int(N_FFT/2)\n",
    "N_MELS = 40\n",
    "LEN_MBE = round(LEN_SAMPLES/int(HOP*NUM_SAMPLES))\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7288c0",
   "metadata": {},
   "source": [
    "#### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96ac99d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6960 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "wet = WetSoundDataset(AUDIO_DIR,\n",
    "                        LEN_MBE,\n",
    "                        NUM_SAMPLES,\n",
    "                        __class_labels,\n",
    "                        device)\n",
    "print(f\"There are {len(wet)} samples in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41d1ce",
   "metadata": {},
   "source": [
    "# SEDnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6fdd24f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEDnet(\n",
      "  (CNN1): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(1, 5), stride=(1, 5), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=True)\n",
      "  )\n",
      "  (CNN2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=True)\n",
      "  )\n",
      "  (CNN3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.5, inplace=True)\n",
      "  )\n",
      "  (RNN): Sequential(\n",
      "    (0): GRU(256, 32, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (1): SelectItem()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): GRU(64, 32, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "    (4): SelectItem()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (FC): Sequential(\n",
      "    (0): TimeDistributed(\n",
      "      (module): Linear(in_features=64, out_features=32, bias=True)\n",
      "    )\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): TimeDistributed(\n",
      "      (module): Linear(in_features=32, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpoblete/miniconda3/envs/ia_257/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = SEDnet(n_class=len(__class_labels))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76ea48",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento de la red convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420bcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import  Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca6e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f040509e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ef8380034b76019b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ef8380034b76019b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpoblete/miniconda3/envs/ia_257/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/vpoblete/miniconda3/envs/ia_257/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448238472/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "2021-10-12 21:11:17,586 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 03:48:06,860 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 3\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 07:22:37,280 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 4\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-13 11:27:20,976 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True)\n",
    "# K-fold Cross Validation model evaluation\n",
    "%tensorboard --logdir logs/fit\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(wet)):\n",
    "    torch.manual_seed(12345) # Inicialización\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    kfold_trainset = Subset(wet,train_ids)\n",
    "    kfold_valset = Subset(wet, val_ids)\n",
    "\n",
    "    trainloader = DataLoader(\n",
    "                    kfold_trainset, \n",
    "                    batch_size=32, shuffle=True)\n",
    "    valloader = DataLoader(\n",
    "                    kfold_valset,\n",
    "                    batch_size=64,shuffle=False)\n",
    "    display(len(trainloader),len(valloader))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = SEDnet(n_class=len(__class_labels))\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3)\n",
    "    criterion = torch.nn.BCELoss(reduction=\"mean\")\n",
    "    trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "    metrics_torch = {\n",
    "        'Accuracy':Accuracy(output_transform=mt.thresholded_output_transform),\n",
    "        'Loss':Loss(criterion,output_transform=mt.thresholded_output_transform),\n",
    "        'Err':mt.er_rate(output_transform=mt.thresholded_output_transform),\n",
    "        'F1':mt.f1_score(output_transform=mt.thresholded_output_transform),\n",
    "    }\n",
    "    train_evaluator = create_supervised_evaluator(model, metrics=metrics_torch, device=device)\n",
    "    valid_evaluator = create_supervised_evaluator(model, metrics=metrics_torch, device=device)\n",
    "    # Contexto de escritura de datos para tensorboard\n",
    "    #tensorboard --logdir=/tmp/tensorboard\n",
    "    \n",
    "    with SummaryWriter(log_dir=f'logs/fit/tensorboard/SEDnet_kfold{fold+1}') as writer:\n",
    "\n",
    "        @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "        def log_results(engine):\n",
    "            # Evaluo el conjunto de entrenamiento\n",
    "            train_evaluator.run(trainloader) \n",
    "            writer.add_scalar(\"train/er\", train_evaluator.state.metrics['Err'], engine.state.epoch)\n",
    "            writer.add_scalar(\"train/f1\", train_evaluator.state.metrics['F1'], engine.state.epoch)\n",
    "            writer.add_scalar(\"train/loss\", train_evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "            writer.add_scalar(\"train/acc\", train_evaluator.state.metrics['Accuracy'], engine.state.epoch)\n",
    "            \n",
    "            # Evaluo el conjunto de validación\n",
    "            valid_evaluator.run(valloader) \n",
    "            er = valid_evaluator.state.metrics['Err']\n",
    "            f1 = valid_evaluator.state.metrics['F1']\n",
    "            acc = valid_evaluator.state.metrics['Loss']\n",
    "            loss = valid_evaluator.state.metrics['Accuracy']\n",
    "            writer.add_scalar(\"valid/er\", er, engine.state.epoch)\n",
    "            writer.add_scalar(\"valid/f1\", f1, engine.state.epoch)\n",
    "            writer.add_scalar(\"valid/loss\", acc, engine.state.epoch)\n",
    "            writer.add_scalar(\"valid/acc\", loss, engine.state.epoch)\n",
    "\n",
    "        def score_function(engine):\n",
    "            val_loss = engine.state.metrics['Err']\n",
    "            return -val_loss\n",
    "\n",
    "        handler = EarlyStopping(patience=100, score_function=score_function, trainer=trainer)\n",
    "\n",
    "        # Guardo el mejor modelo en validación\n",
    "        best_model_handler = ModelCheckpoint(dirname='models/', require_empty=False, filename_prefix=\"best\", n_saved=1,\n",
    "                                             score_function=lambda engine: -engine.state.metrics['Err'],\n",
    "                                             score_name=\"val_error\")\n",
    "\n",
    "        # Lo siguiente se ejecuta cada ves que termine el loop de validación\n",
    "        valid_evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                    best_model_handler, {'SEDnet{}'.format(fold): model})\n",
    "        valid_evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "        trainer.run(trainloader, max_epochs=max_epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c2ae1fa8f4c727dd589fb2bff9478f53eaab7b86ff56190838baa3205820518"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
