{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e30e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import sklearn.model_selection\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from sklearn import metrics as mt\n",
    "from ignite.engine import  Engine, Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, Metric, ClassificationReport\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from codes import utils, metric\n",
    "from codes.models import SEDnet\n",
    "from codes.dataset2 import WetSoundDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import sigmoid\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0678fd",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5169d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bdc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = os.path.join(main,\"features/test_set/\")\n",
    "SAMPLE_RATE = 44100\n",
    "LEN_SEC = 300\n",
    "LEN_SAMPLES = LEN_SEC*SAMPLE_RATE\n",
    "NUM_SAMPLES = 1024  #Cantidad de secuencias , no largo de secuencia 12920/40\n",
    "__class_labels = {\n",
    "'perro'    : 0,\n",
    "'rana'     : 1,\n",
    "'lluvia'   : 2,\n",
    "'motor'    : 3,\n",
    "'ave'      : 4\n",
    "}\n",
    "N_FFT = 2048\n",
    "HOP = int(N_FFT/2)\n",
    "N_MELS = 40\n",
    "LEN_MBE = round(LEN_SAMPLES/int(HOP*NUM_SAMPLES))\n",
    "frames_1_sec = int(SAMPLE_RATE/(N_FFT/2.0))\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29db2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "wet = WetSoundDataset(AUDIO_DIR,\n",
    "                        LEN_MBE,\n",
    "                        NUM_SAMPLES,\n",
    "                        __class_labels,\n",
    "                        device)\n",
    "print(f\"There are {len(wet)} samples in the dataset.\")\n",
    "test_loader = DataLoader(wet, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d366f3b",
   "metadata": {},
   "source": [
    "## Cargar modelos entrenados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1d2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_models = \"models/\"\n",
    "results = dict()\n",
    "for fold_model in os.listdir(path_models):\n",
    "    filter_file = fold_model.split(\".\")\n",
    "    if len(filter_file)>1:\n",
    "        if filter_file[2]==\"pt\":\n",
    "            print(fold_model)\n",
    "            model = SEDnet(len(__class_labels))\n",
    "            model.load_state_dict(torch.load(path_models+fold_model))\n",
    "            model.to(device)\n",
    "\n",
    "            #pred = list()\n",
    "            #targets = list()\n",
    "            i=0\n",
    "            for data,label in test_loader:\n",
    "                with torch.no_grad():\n",
    "                    pred_i = model.forward(data)\n",
    "                label = label.to('cpu')\n",
    "                pred_i = pred_i.to('cpu')\n",
    "                pred_i,label = metric.thresholded_output_transform([pred_i,label])\n",
    "                pred_i = pred_i.view(pred_i.shape[1]*pred_i.shape[0],pred_i.shape[2])\n",
    "                label = label.view(label.shape[1]*label.shape[0],label.shape[2])\n",
    "                if i == 0:\n",
    "                    pred = pred_i\n",
    "                    targets = label\n",
    "                else:\n",
    "                    pred = torch.cat((pred,pred_i))\n",
    "                    targets = torch.cat((targets,label))\n",
    "                i+=1\n",
    "                del pred_i\n",
    "                del data\n",
    "                del label\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            pred = pred.numpy()\n",
    "            targets = targets.numpy()\n",
    "\n",
    "            metrics_data = metric.compute_scores_orig(pred, targets,frames_1_sec)\n",
    "\n",
    "            results[fold_model]=metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "257",
   "language": "python",
   "name": "257"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
